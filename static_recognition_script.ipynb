{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Konfiguracja</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Instalacja bibliotek</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe\n",
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Funkcje pomocnicze</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importowanie i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekstrakcja znormalizowanych punktów kluczowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_results(results):\n",
    "    smallestX = 1\n",
    "    biggestX = 0\n",
    "    smallestY = 1\n",
    "    biggestY = 0\n",
    "    smallestZ = 1\n",
    "    biggestZ = 0\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark] if results.left_hand_landmarks else [[0,0,0] for i in range(21)]) \n",
    "    for landmark in lh:\n",
    "        newX = landmark[0]\n",
    "        newY = landmark[1]\n",
    "        newZ = landmark[2]\n",
    "        if(smallestX>newX):\n",
    "            smallestX = newX \n",
    "        if(biggestX<newX):\n",
    "            biggestX = newX \n",
    "        if(smallestY>newY):\n",
    "            smallestY = newY \n",
    "        if(biggestY<newY):\n",
    "            biggestY = newY \n",
    "        if(smallestZ>newZ):\n",
    "            smallestZ = newZ \n",
    "        if(biggestZ<newZ):\n",
    "            biggestZ = newZ \n",
    "        \n",
    "    normalizedLandmarks = []\n",
    "    for landmark in lh:\n",
    "        x_norm = (landmark[0]-smallestX)/(biggestX-smallestX)\n",
    "        y_norm = (landmark[1]-smallestY)/(biggestY-smallestY)\n",
    "        z_norm = (landmark[2]-smallestZ)/(biggestZ-smallestZ)\n",
    "        if math.isnan(x_norm):\n",
    "            x_norm = 0.0\n",
    "        if math.isnan(y_norm):\n",
    "            y_norm = 0.0\n",
    "        if math.isnan(z_norm):\n",
    "            z_norm = 0.0\n",
    "        normalizedLandmarks.append([x_norm,y_norm,z_norm])\n",
    "    return np.array(normalizedLandmarks).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detekcja punktów kluczowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_cv2_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False           \n",
    "    results = model.process(image)    \n",
    "    image.flags.writeable = True      \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rysowanie rozpoznanych punktów kluczowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hands_landmarks(image, results):\n",
    "     mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(70,200,70), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(70,70,70), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "     mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(200,70,70), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(70,70,70), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Zbieranie punktów kluczowych dłoni</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importowanie oraz konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stałe i zmienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATIC_SYMBOLS = [\"1\",\"2\",\"3\",\"4\",\"5\",\"A\",\"B\",\"C\",\"E\",\"I\",\"L\",\"M\",\"N\",\"O\",\"P\",\"R\",\"S\",\"T\",\"U\",\"W\",\"Y\"]\n",
    "SYMBOLS_PATH = \"staticSymbols\"\n",
    "sequence_length = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzenie folderów dla statycznych znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in STATIC_SYMBOLS: \n",
    "    try: \n",
    "        os.makedirs(os.path.join(SYMBOLS_PATH, symbol))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbieranie znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_symbols = [\"Y\"]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for symbol in recorded_symbols:\n",
    "        for frame_num in range(sequence_length+1):\n",
    "            ret, frame = cap.read()\n",
    "            image, results = mediapipe_cv2_detection(frame, holistic)\n",
    "            draw_hands_landmarks(image, results)\n",
    "\n",
    "            if frame_num == 0: \n",
    "                cv2.rectangle(image, (0,440), (640, 480), (20, 20, 20), -1)\n",
    "                cv2.putText(image, 'COLLECT IN: 3', (20,470),cv2.FONT_HERSHEY_TRIPLEX, 1, (35, 184, 75), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Sign: {}'.format(symbol), (330,465), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (250, 250, 250), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(1000)\n",
    "                cv2.rectangle(image, (0,440), (640, 480), (20, 20, 20), -1)\n",
    "                cv2.putText(image, 'COLLECT IN: 2', (20,470),cv2.FONT_HERSHEY_TRIPLEX, 1, (35, 184, 75), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Sign: {}'.format(symbol), (330,465), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (250, 250, 250), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(1000)\n",
    "                cv2.rectangle(image, (0,440), (640, 480), (20, 20, 20), -1)\n",
    "                cv2.putText(image, 'COLLECT IN: 1', (20,470),cv2.FONT_HERSHEY_TRIPLEX, 1, (35, 184, 75), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Sign: {}'.format(symbol), (330,465), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (250, 250, 250), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(1000)\n",
    "                cv2.rectangle(image, (0,440), (640, 480), (20, 20, 20), -1)\n",
    "                cv2.putText(image, 'GET READY', (20,470),cv2.FONT_HERSHEY_TRIPLEX, 1, (61, 223, 235), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Sign: {}'.format(symbol), (330,465), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (250, 250, 250), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(500)\n",
    "            else: \n",
    "                cv2.rectangle(image, (0,440), (640, 480), (20, 20, 20), -1)\n",
    "                cv2.putText(image, 'COLLECTING NOW', (20,470),cv2.FONT_HERSHEY_TRIPLEX, 1, (25, 29, 250), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Sign: {}'.format(symbol), (330,465), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (250, 250, 250), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                keypoints = normalize_results(results)\n",
    "                npy_path = os.path.join(SYMBOLS_PATH, symbol, str(frame_num))\n",
    "                np.save(npy_path,keypoints)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "                    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Szkolenie modelu</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stałe i zmienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, 'A': 5, 'B': 6, 'C': 7, 'E': 8, 'I': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 13, 'P': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 18, 'W': 19, 'Y': 20}\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join('StaticLogs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(STATIC_SYMBOLS)}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych z tablic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilities, labels = [], []\n",
    "for symbol in STATIC_SYMBOLS:\n",
    "    for frame_num in range(1,sequence_length+1):\n",
    "        res = np.load(os.path.join(SYMBOLS_PATH, symbol, \"{}.npy\".format(str(frame_num))))\n",
    "        posibilities.append(res)\n",
    "        labels.append(label_map[symbol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie i podział na zbiory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: \n",
      "(1260, 63)\n",
      "y shape: \n",
      "(1260, 21)\n",
      "X_train shape: \n",
      "(1008, 63)\n",
      "y_train shape: \n",
      "(1008, 21)\n",
      "x_val shape: \n",
      "(126, 63)\n",
      "y_val shape: \n",
      "(126, 21)\n",
      "x_test shape: \n",
      "(126, 63)\n",
      "y_test shape: \n",
      "(126, 21)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(posibilities)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X, y = shuffle(X, y, random_state=15)\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y,stratify=y,test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test,stratify=y_val_test,test_size=0.5)\n",
    "\n",
    "print(\"X shape: \")\n",
    "print(X.shape)\n",
    "print(\"y shape: \")\n",
    "print(y.shape)\n",
    "print(\"X_train shape: \")\n",
    "print(X_train.shape)\n",
    "print(\"y_train shape: \")\n",
    "print(y_train.shape)\n",
    "print(\"x_val shape: \")\n",
    "print(X_val.shape)\n",
    "print(\"y_val shape: \")\n",
    "print(y_val.shape)\n",
    "print(\"x_test shape: \")\n",
    "print(X_test.shape)\n",
    "print(\"y_test shape: \")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizacja i szkolenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=63,activation='sigmoid'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(np.array(STATIC_SYMBOLS).shape[0], activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "fit_history = model.fit(X_train, y_train, epochs=100, callbacks=[tb_callback],validation_data=(X_val,y_val),verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzenie struktury folderów do zapisu wyników szkoleń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.makedirs('static_comparison')\n",
    "    os.makedirs(os.path.join('static_comparison','plots'))\n",
    "    os.makedirs(os.path.join('static_comparison','matrix'))\n",
    "    os.makedirs(os.path.join('static_comparison','models'))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisanie modelu i prezentacja podsumowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                2048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,525\n",
      "Trainable params: 5,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_save = f\"static_D32-D64\"\n",
    "model_save_name = f\"static_comparison/models/PJM_ST_{model_save}.h5\"\n",
    "model.save('models/PJM_left_hand_v4.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytywanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/PJM_left_hand_v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Dokładność i macierze błędów </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importowanie z bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "confusion_mtrx = confusion_matrix(ytrue,yhat)\n",
    "accuracy = accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokładność modelu matematycznego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy: \")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór funkcji do tworzenia przebiegów szkoleń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(fit_history,save_name):\n",
    "    plt.figure(figsize = (15,12))\n",
    "    plt.plot(fit_history.history['loss'])\n",
    "    plt.plot(fit_history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training','validation'],loc='upper left')\n",
    "    plt.savefig(f\"static_comparison/plots/{save_name}_loss.png\") \n",
    "    plt.close()\n",
    "\n",
    "def acc_plot(fit_history,save_name):\n",
    "    plt.figure(figsize = (15,12))\n",
    "    plt.plot(fit_history.history['categorical_accuracy'])\n",
    "    plt.plot(fit_history.history['val_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training','validation'],loc='upper left')\n",
    "    plt.savefig(f\"static_comparison/plots/{save_name}_acc.png\") \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierze błędów dla wszystkich statycznych znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matrices(confusion_mtrx_train,confusion_mtrx_val,confusion_mtrx_test,save_name):\n",
    "    df_cm_train = pd.DataFrame(confusion_mtrx_train, index = [i for i in STATIC_SYMBOLS],\n",
    "                    columns = [i for i in STATIC_SYMBOLS])\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sn.heatmap(df_cm_train, annot=True,cmap=plt.cm.Greens)\n",
    "    plt.savefig(f\"static_comparison/matrix/{save_name}_train.png\") \n",
    "    plt.close()\n",
    "\n",
    "    df_cm_val = pd.DataFrame(confusion_mtrx_val, index = [i for i in STATIC_SYMBOLS],\n",
    "                    columns = [i for i in STATIC_SYMBOLS])\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sn.heatmap(df_cm_val, annot=True,cmap=plt.cm.Oranges)\n",
    "    plt.savefig(f\"static_comparison/matrix/{save_name}_val.png\") \n",
    "    plt.close()\n",
    "\n",
    "    df_cm_test = pd.DataFrame(confusion_mtrx_test, index = [i for i in STATIC_SYMBOLS],\n",
    "                    columns = [i for i in STATIC_SYMBOLS])\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sn.heatmap(df_cm_test, annot=True,cmap=plt.cm.Blues)\n",
    "    plt.savefig(f\"static_comparison/matrix/{save_name}_test.png\") \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja szkoląca, zapisująca model, przebiegi szkolenia oraz wyniki dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(fit_history,model_save)\n",
    "acc_plot(fit_history,model_save)\n",
    "yhat_train = model.predict(X_train)\n",
    "ytrue_train = np.argmax(y_train, axis=1).tolist()\n",
    "yhat_train = np.argmax(yhat_train, axis=1).tolist()\n",
    "confusion_mtrx_train = confusion_matrix(ytrue_train,yhat_train)\n",
    "accuracy_train = accuracy_score(ytrue_train, yhat_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "confusion_mtrx_test = confusion_matrix(ytrue,yhat)\n",
    "accuracy_test = accuracy_score(ytrue, yhat)\n",
    "\n",
    "yhat_val = model.predict(X_val)\n",
    "ytrue_val = np.argmax(y_val, axis=1).tolist()\n",
    "yhat_val = np.argmax(yhat_val, axis=1).tolist()\n",
    "confusion_mtrx_val = confusion_matrix(ytrue_val,yhat_val)\n",
    "accuracy_val = accuracy_score(ytrue_val, yhat_val)\n",
    "\n",
    "save_matrices(confusion_mtrx_train,confusion_mtrx_val,confusion_mtrx_test,model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static_D32-D64 TRAIN 100.0%, VAL 100.0% , TEST 100.0%\n"
     ]
    }
   ],
   "source": [
    "model_summary = f\"{model_save} TRAIN {round(accuracy_train*100,2)}%, VAL {round(accuracy_val*100,2)}% , TEST {round(accuracy_test*100,2)}%\"\n",
    "print(model_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
